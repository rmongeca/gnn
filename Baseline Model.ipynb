{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from typing import Dict\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "limit = 1000\n",
    "training_dir = \"/home/rmonge/UPC/TFM/gnn-qm9/data/training\"\n",
    "training_fn = [os.path.join(training_dir, fn) for fn in os.listdir(training_dir)\n",
    "               if not fn.startswith(\".\")][:limit]\n",
    "test_dir = \"/home/rmonge/UPC/TFM/gnn-qm9/data/test\"\n",
    "test_fn = [os.path.join(test_dir, fn) for fn in os.listdir(test_dir) if not fn.startswith(\".\")][:limit]\n",
    "target = \"dipole_moment\"\n",
    "\n",
    "print(f\"Training samples: {len(training_fn)}\")\n",
    "print(f\"Test samples: {len(test_fn)}\")\n",
    "\n",
    "training = tf.data.Dataset.from_generator(\n",
    "    **GNNInput.get_data_generator(training_fn, target))\\\n",
    "    .shuffle(len(training_fn), reshuffle_each_iteration=True).batch(1)\n",
    "test = tf.data.Dataset.from_generator(\n",
    "    **GNNInput.get_data_generator(test_fn, target))\\\n",
    "    .shuffle(len(test_fn), reshuffle_each_iteration=True).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec, y_spec = training.element_spec\n",
    "\n",
    "hidden_state_size = 20\n",
    "# message_size = hidden_state_size + graph_spec.edge_features.shape[-1]  # For ConcatenationMessage\n",
    "message_size = 30\n",
    "message_passing_iterations = 5\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(hidden_state_size=hidden_state_size, message_size=message_size,\n",
    "            message_passing_iterations=message_passing_iterations,\n",
    "            message_passing=EdgeNetMessagePassing,\n",
    "#             message_passing=ConcatenationMessage,\n",
    "            output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1.935e-4, decay_steps=900, end_learning_rate=1.84e-4, power=1.0\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_schedule)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "log_name = f\"gnn_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "log_dir = f\"/home/rmonge/UPC/TFM/ignnition_data/CheckPoint/{log_name}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmonge/UPC/TFM/gnn-qm9/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1000 [..............................] - ETA: 0s - loss: 16.2329 - mean_absolute_error: 4.0290WARNING:tensorflow:From /home/rmonge/UPC/TFM/gnn-qm9/.venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rmonge/UPC/TFM/gnn-qm9/.venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1000 [..............................] - ETA: 4:06 - loss: 13.7738 - mean_absolute_error: 3.6964WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0760s vs `on_train_batch_end` time: 0.4165s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0760s vs `on_train_batch_end` time: 0.4165s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 53s 53ms/step - loss: 2.7168 - mean_absolute_error: 1.2462 - val_loss: 2.2847 - val_mean_absolute_error: 1.1750\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   0/1000 [..............................] - 0s 0s/step - loss: 2.7168 - mean_absolute_error: 1.2462 - val_loss: 2.2847 - val_mean_absolute_error: 1.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.34279108047485"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "loss = model.fit(\n",
    "    training, epochs=10, steps_per_epoch=1000,\n",
    "    validation_data=test, validation_freq=1, validation_steps=1000,\n",
    "    callbacks=[tensorboard_callback], use_multiprocessing=True)\n",
    "time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step - loss: 2.2847 - mean_absolute_error: 1.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.540741682052612"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "metric = model.evaluate(test)\n",
    "time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2847254276275635, 1.1749879121780396]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
